{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Notebook 02 – Feature Engineering cho Home Credit Default Risk\n",
        "# Mục tiêu:\n",
        "# - Tạo bộ feature hoàn chỉnh từ tất cả bảng: application, bureau, prev, pos, inst, credit_card\n",
        "# - Không scaling, không WOE, không PCA\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import gc\n",
        "import warnings\n",
        "from typing import Tuple\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "DATA_DIR = \"/content/drive/MyDrive/home_credit\"\n",
        "OUTPUT_DIR = os.path.join(DATA_DIR, \"processed\")\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "def RELU(series: pd.Series) -> pd.Series:\n",
        "    return series.apply(lambda x: max(0, x))\n",
        "\n",
        "def safe_divide(numerator, denominator, fill_value=np.nan):\n",
        "    \"\"\"\n",
        "    Chia an toàn:\n",
        "    - tránh division by zero\n",
        "    - có thể dùng cho Series hoặc ndarray\n",
        "    \"\"\"\n",
        "    numerator = numerator.astype(float)\n",
        "    denominator = denominator.astype(float)\n",
        "    result = numerator / (denominator + 1e-9)\n",
        "    if isinstance(result, pd.Series):\n",
        "        mask = (denominator == 0) | denominator.isna()\n",
        "        result[mask] = fill_value\n",
        "    else:\n",
        "        mask = (denominator == 0)\n",
        "        result[mask] = fill_value\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "3z6FcCwQ7YUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 1. APPLICATION TABLE - MAIN FEATURES\n",
        "# ============================================================================\n",
        "\n",
        "def process_application(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Xử lý bảng application_train/test\n",
        "    - Anomaly handling\n",
        "    - Flags & indicators\n",
        "    - Ratios (income, credit, payment)\n",
        "    - EXT_SOURCE features\n",
        "    - Time transforms\n",
        "    - Group-based features\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 1.1. ANOMALY & MISSING HANDLING\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    # DAYS_EMPLOYED anomaly\n",
        "    df['FLAG_EMPLOYED_ANOMALY'] = (df['DAYS_EMPLOYED'] == 365243).astype(int)\n",
        "    df.loc[df['DAYS_EMPLOYED'] == 365243, 'DAYS_EMPLOYED'] = np.nan\n",
        "\n",
        "    # CODE_GENDER XNA\n",
        "    df['FLAG_GENDER_XNA'] = (df['CODE_GENDER'] == 'XNA').astype(int)\n",
        "    df['CODE_GENDER'] = df['CODE_GENDER'].replace('XNA', 'F')\n",
        "\n",
        "    # Missing gradings indicator\n",
        "    grading_cols = [col for col in df.columns if '_AVG' in col or '_MODE' in col]\n",
        "    df['MISSING_GRADINGS'] = df[grading_cols].isna().sum(axis=1)\n",
        "\n",
        "    # Clean categorical anomalies\n",
        "    df['EMERGENCYSTATE_MODE'] = df['EMERGENCYSTATE_MODE'].fillna('No')\n",
        "    df['OCCUPATION_TYPE'] = df['OCCUPATION_TYPE'].replace({\n",
        "        'IT staff': 'High skill tech staff',\n",
        "        'Realty agents': 'Sales staff'\n",
        "    })\n",
        "\n",
        "    # Simplify categories\n",
        "    occupation_to_drop = ['High skill tech staff', 'HR staff', 'Secretaries',\n",
        "                          'Cleaning staff', 'Cooking staff', 'Waiters/barmen staff',\n",
        "                          'Private service staff', 'Low-skill Laborers', 'Security staff']\n",
        "    df['OCCUPATION_TYPE'] = df['OCCUPATION_TYPE'].replace(occupation_to_drop, np.nan)\n",
        "\n",
        "    df['FONDKAPREMONT_MODE'] = df['FONDKAPREMONT_MODE'].replace(\n",
        "        ['not specified', 'org spec account', 'reg oper account'], np.nan\n",
        "    )\n",
        "\n",
        "    # Drop sparse columns\n",
        "    df = df.drop(columns=['HOUSETYPE_MODE', 'WALLSMATERIAL_MODE'], errors='ignore')\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 1.2. FLAGS & INDICATORS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    # Family structure\n",
        "    df['cnt_non_child'] = df['CNT_FAM_MEMBERS'] - df['CNT_CHILDREN']\n",
        "    df['FLAG_SINGLE'] = (df['CNT_FAM_MEMBERS'] == 1).astype(int)\n",
        "    df['FLAG_HAS_CHILDREN'] = (df['CNT_CHILDREN'] > 0).astype(int)\n",
        "    df['child_to_non_child_ratio'] = safe_divide(\n",
        "        df['CNT_CHILDREN'],\n",
        "        df['cnt_non_child']\n",
        "    )\n",
        "\n",
        "    # Address reliability\n",
        "    df['RELIABILITY_IN_CUSTOMER_CITY'] = (\n",
        "        df['REG_CITY_NOT_LIVE_CITY'] +\n",
        "        df['REG_CITY_NOT_WORK_CITY'] +\n",
        "        df['REG_REGION_NOT_LIVE_REGION'] +\n",
        "        df['REG_REGION_NOT_WORK_REGION'] +\n",
        "        df['LIVE_CITY_NOT_WORK_CITY'] +\n",
        "        df['LIVE_REGION_NOT_WORK_REGION']\n",
        "    )\n",
        "\n",
        "    # Contact information\n",
        "    df['SUM_CONTACTS'] = (\n",
        "        df['FLAG_MOBIL'] + df['FLAG_EMP_PHONE'] +\n",
        "        df['FLAG_WORK_PHONE'] + df['FLAG_CONT_MOBILE'] +\n",
        "        df['FLAG_PHONE'] + df['FLAG_EMAIL']\n",
        "    )\n",
        "    df['HAS_EMAIL'] = df['FLAG_EMAIL']\n",
        "    df['HAS_WORK_PHONE'] = df['FLAG_WORK_PHONE']\n",
        "\n",
        "    # Document flags aggregation\n",
        "    doc_cols = [col for col in df.columns if 'FLAG_DOCUMENT_' in col]\n",
        "    df['DOCUMENT_COUNT'] = df[doc_cols].sum(axis=1)\n",
        "    df['HAS_DOCUMENT'] = df[doc_cols].max(axis=1)\n",
        "    df['NEW_DOC_IND_AVG'] = df[doc_cols].mean(axis=1)\n",
        "    df['NEW_DOC_IND_STD'] = df[doc_cols].std(axis=1)\n",
        "    df = df.drop(columns=doc_cols)\n",
        "\n",
        "    # Credit bureau enquiries\n",
        "    bureau_cols = ['AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY',\n",
        "                   'AMT_REQ_CREDIT_BUREAU_WEEK', 'AMT_REQ_CREDIT_BUREAU_MON',\n",
        "                   'AMT_REQ_CREDIT_BUREAU_QRT', 'AMT_REQ_CREDIT_BUREAU_YEAR']\n",
        "    df['TOTAL_ENQUIRIES_CREDIT_BUREAU'] = df[bureau_cols].sum(axis=1)\n",
        "    df['PCTG_ENQUIRIES_WEEK'] = safe_divide(\n",
        "        df['AMT_REQ_CREDIT_BUREAU_WEEK'],\n",
        "        df['TOTAL_ENQUIRIES_CREDIT_BUREAU']\n",
        "    )\n",
        "    df['PCTG_ENQUIRIES_MON'] = safe_divide(\n",
        "        df['AMT_REQ_CREDIT_BUREAU_MON'],\n",
        "        df['TOTAL_ENQUIRIES_CREDIT_BUREAU']\n",
        "    )\n",
        "    df['PCTG_ENQUIRIES_QRT'] = safe_divide(\n",
        "        df['AMT_REQ_CREDIT_BUREAU_QRT'],\n",
        "        df['TOTAL_ENQUIRIES_CREDIT_BUREAU']\n",
        "    )\n",
        "    df['PCTG_ENQUIRIES_YEAR'] = safe_divide(\n",
        "        df['AMT_REQ_CREDIT_BUREAU_YEAR'],\n",
        "        df['TOTAL_ENQUIRIES_CREDIT_BUREAU']\n",
        "    )\n",
        "    df = df.drop(columns=['AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY',\n",
        "                          'AMT_REQ_CREDIT_BUREAU_WEEK'])\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 1.3. RATIOS - Core Credit Scoring Features\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    # Income ratios\n",
        "    df['ANNUITY_INCOME_PERC'] = safe_divide(df['AMT_ANNUITY'], df['AMT_INCOME_TOTAL'])\n",
        "    df['CREDIT_INCOME_PERC'] = safe_divide(df['AMT_CREDIT'], df['AMT_INCOME_TOTAL'])\n",
        "    df['income_credit_percentage'] = safe_divide(df['AMT_INCOME_TOTAL'], df['AMT_CREDIT'])\n",
        "\n",
        "    # Payment ability\n",
        "    df['PAYMENT_RATE'] = safe_divide(df['AMT_ANNUITY'], df['AMT_CREDIT'])\n",
        "    df['credit_to_annuity_ratio'] = safe_divide(df['AMT_CREDIT'], df['AMT_ANNUITY'])\n",
        "\n",
        "    # Per person ratios\n",
        "    df['income_per_person'] = safe_divide(df['AMT_INCOME_TOTAL'], df['CNT_FAM_MEMBERS'])\n",
        "    df['income_per_child'] = safe_divide(\n",
        "        df['AMT_INCOME_TOTAL'],\n",
        "        df['CNT_CHILDREN'] + 1\n",
        "    ) * (df['CNT_CHILDREN'] > 0)\n",
        "    df['income_per_non_child'] = safe_divide(\n",
        "        df['AMT_INCOME_TOTAL'],\n",
        "        df['cnt_non_child']\n",
        "    )\n",
        "\n",
        "    df['credit_per_person'] = safe_divide(df['AMT_CREDIT'], df['CNT_FAM_MEMBERS'])\n",
        "    df['credit_per_child'] = safe_divide(df['AMT_CREDIT'], df['CNT_CHILDREN'] + 1)\n",
        "    df['credit_per_non_child'] = safe_divide(df['AMT_CREDIT'], df['cnt_non_child'])\n",
        "\n",
        "    # Goods ratios\n",
        "    df['credit_to_goods_ratio'] = safe_divide(df['AMT_CREDIT'], df['AMT_GOODS_PRICE'])\n",
        "    df['CREDIT_GOODS_PRICE_RATIO1'] = safe_divide(\n",
        "        df['AMT_CREDIT'] - df['AMT_GOODS_PRICE'],\n",
        "        df['AMT_GOODS_PRICE']\n",
        "    )\n",
        "    df['CREDIT_GOODS_PRICE_RATIO2'] = safe_divide(\n",
        "        df['AMT_CREDIT'] - df['AMT_GOODS_PRICE'],\n",
        "        df['AMT_CREDIT']\n",
        "    )\n",
        "    df['CREDIT_DOWN_PAYMENT'] = df['AMT_GOODS_PRICE'] - df['AMT_CREDIT']\n",
        "\n",
        "    # Time-based ratios\n",
        "    df['DAYS_EMPLOYED_FILLED'] = df['DAYS_EMPLOYED'].fillna(0)\n",
        "    df['days_employed_percentage'] = safe_divide(\n",
        "        df['DAYS_EMPLOYED_FILLED'],\n",
        "        df['DAYS_BIRTH']\n",
        "    )\n",
        "    df['car_to_birth_ratio'] = RELU(safe_divide(df['OWN_CAR_AGE'], df['DAYS_BIRTH']))\n",
        "    df['car_to_employ_ratio'] = RELU(safe_divide(\n",
        "        df['OWN_CAR_AGE'],\n",
        "        df['DAYS_EMPLOYED_FILLED']\n",
        "    ))\n",
        "    df['phone_to_birth_ratio'] = RELU(safe_divide(\n",
        "        df['DAYS_LAST_PHONE_CHANGE'],\n",
        "        df['DAYS_BIRTH']\n",
        "    ))\n",
        "    df['phone_to_employ_ratio'] = RELU(safe_divide(\n",
        "        df['DAYS_LAST_PHONE_CHANGE'],\n",
        "        df['DAYS_EMPLOYED_FILLED']\n",
        "    ))\n",
        "\n",
        "    # Debt burden\n",
        "    df['DEBT_BURDEN_PER_WORKING_DAY'] = safe_divide(\n",
        "        df['PAYMENT_RATE'],\n",
        "        df['DAYS_EMPLOYED_FILLED']\n",
        "    )\n",
        "    df['DEBT_BURDEN_PER_LIFE_DAY'] = safe_divide(df['PAYMENT_RATE'], df['DAYS_BIRTH'])\n",
        "\n",
        "    # Building ratios\n",
        "    df['LIVINGAREA_AVG'] = df['LIVINGAREA_AVG'].fillna(0)\n",
        "    df['TOTALAREA_MODE'] = df['TOTALAREA_MODE'].fillna(0)\n",
        "    df['RATIO_AMT_GOODS_PRICE_TO_LIVINGAREA'] = safe_divide(\n",
        "        df['AMT_GOODS_PRICE'],\n",
        "        df['LIVINGAREA_AVG'].clip(0.05, 999)\n",
        "    ) * (df['LIVINGAREA_AVG'] > 0)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 1.4. EXT_SOURCE FEATURES\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    df['ext_sources_mean'] = df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n",
        "    df['ext_sources_sum'] = df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].sum(axis=1)\n",
        "    df['ext_sources_var'] = df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].var(axis=1)\n",
        "    df['ext_sources_weighted'] = (\n",
        "        df['EXT_SOURCE_1'] * 2 +\n",
        "        df['EXT_SOURCE_2'] * 3 +\n",
        "        df['EXT_SOURCE_3'] * 4\n",
        "    )\n",
        "    df['EXT_SOURCE_MISSING_VALUES'] = df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].isna().sum(axis=1)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 1.5. TIME TRANSFORMS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    # Cyclic encoding for hour\n",
        "    df['sin_HOUR_APPR_PROCESS_START'] = np.sin(2 * np.pi * df['HOUR_APPR_PROCESS_START'] / 24)\n",
        "    df['cos_HOUR_APPR_PROCESS_START'] = np.cos(2 * np.pi * df['HOUR_APPR_PROCESS_START'] / 24)\n",
        "    df = df.drop(columns=['HOUR_APPR_PROCESS_START'])\n",
        "\n",
        "    # Weekday simplification\n",
        "    df['WEEKDAY_APPR_PROCESS_START'] = df['WEEKDAY_APPR_PROCESS_START'].replace({\n",
        "        'MONDAY': 'week_day', 'TUESDAY': 'week_day', 'WEDNESDAY': 'week_day',\n",
        "        'THURSDAY': 'week_day', 'FRIDAY': 'week_day',\n",
        "        'SATURDAY': 'weekend', 'SUNDAY': 'weekend'\n",
        "    })\n",
        "\n",
        "    # Age in years\n",
        "    df['AGE_INT'] = -df['DAYS_BIRTH'] // 365\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 1.6. GROUP-BASED FEATURES\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    # Education mapping\n",
        "    edu_map = {\n",
        "        'Lower secondary': 0,\n",
        "        'Secondary / secondary special': 1,\n",
        "        'Incomplete higher': 2,\n",
        "        'Higher education': 3,\n",
        "        'Academic degree': 5\n",
        "    }\n",
        "    df['NAME_EDUCATION_TYPE'] = df['NAME_EDUCATION_TYPE'].map(edu_map).fillna(0).astype(int)\n",
        "\n",
        "    # Organization simplification\n",
        "    def group_organizations(org_type):\n",
        "        if not isinstance(org_type, str):\n",
        "            return org_type\n",
        "        if 'Trade' in org_type:\n",
        "            return np.nan\n",
        "        elif 'Industry' in org_type:\n",
        "            return 'Industry'\n",
        "        elif 'Business' in org_type:\n",
        "            return 'Business Entity'\n",
        "        elif 'Transport' in org_type:\n",
        "            return 'Transport'\n",
        "        elif 'University' in org_type or 'School' in org_type:\n",
        "            return 'School'\n",
        "        elif org_type in ['Unknown', 'XNA', 'Insurance', 'Services', 'Restaurant',\n",
        "                          'Housing', 'Hotel', 'Agriculture', 'Other']:\n",
        "            return np.nan\n",
        "        return org_type\n",
        "\n",
        "    df['ORGANIZATION_TYPE'] = df['ORGANIZATION_TYPE'].apply(group_organizations)\n",
        "\n",
        "    # Group-based income features\n",
        "    med_income_org_edu = df.groupby(['ORGANIZATION_TYPE', 'NAME_EDUCATION_TYPE'])['AMT_INCOME_TOTAL'].transform('median')\n",
        "    med_income_org = df.groupby('ORGANIZATION_TYPE')['AMT_INCOME_TOTAL'].transform('median')\n",
        "\n",
        "    df['income_ratio'] = safe_divide(df['AMT_INCOME_TOTAL'], med_income_org_edu)\n",
        "    df['income_ratio2'] = safe_divide(df['AMT_INCOME_TOTAL'], med_income_org)\n",
        "    df['true_annuity_div_income'] = safe_divide(df['AMT_ANNUITY'], med_income_org_edu)\n",
        "    df['true_annuity_div_income2'] = safe_divide(df['AMT_ANNUITY'], med_income_org)\n",
        "\n",
        "    # Social circle features\n",
        "    df['OBS_30_CNT_SOCIAL_CIRCLE'] = df['OBS_30_CNT_SOCIAL_CIRCLE'].clip(0, 50)\n",
        "    df['DEF_30_CNT_SOCIAL_CIRCLE'] = df['DEF_30_CNT_SOCIAL_CIRCLE'].clip(0, 50)\n",
        "    df['OBS_60_CNT_SOCIAL_CIRCLE'] = df['OBS_60_CNT_SOCIAL_CIRCLE'].clip(0, 50)\n",
        "    df['DEF_60_CNT_SOCIAL_CIRCLE'] = df['DEF_60_CNT_SOCIAL_CIRCLE'].clip(0, 50)\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "26nuHC3j7h5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 2. BUREAU + BUREAU_BALANCE\n",
        "# ============================================================================\n",
        "\n",
        "def process_bureau_balance(bureau_balance: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Xử lý bureau_balance - DPD buckets\"\"\"\n",
        "    bb = bureau_balance.copy()\n",
        "\n",
        "    # Map STATUS to DPD buckets\n",
        "    dpd_map = {\n",
        "        '0': 'no_dpd',\n",
        "        '1': 'dpd_1_29',\n",
        "        '2': 'dpd_30_59',\n",
        "        '3': 'dpd_60_89',\n",
        "        '4': 'dpd_90_119',\n",
        "        '5': 'dpd_120_plus',\n",
        "        'C': 'no_info_or_closed',\n",
        "        'X': 'no_info_or_closed'\n",
        "    }\n",
        "    bb['STATUS_GROUP'] = bb['STATUS'].map(dpd_map)\n",
        "\n",
        "    # Aggregation per SK_ID_BUREAU\n",
        "    bb_agg = bb.groupby('SK_ID_BUREAU').agg({\n",
        "        'MONTHS_BALANCE': 'count',\n",
        "        'STATUS_GROUP': lambda x: (x == 'no_dpd').sum()\n",
        "    }).reset_index()\n",
        "    bb_agg.columns = ['SK_ID_BUREAU', 'BB_MONTHS_COUNT', 'BB_MONTHS_NO_DPD']\n",
        "    bb_agg['BB_RATIO_NO_DPD'] = bb_agg['BB_MONTHS_NO_DPD'] / bb_agg['BB_MONTHS_COUNT']\n",
        "\n",
        "    return bb_agg\n",
        "\n",
        "\n",
        "def process_bureau(bureau_path: str, bureau_balance_path: str = None) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Xử lý bảng bureau với:\n",
        "    - Cleaning anomalies\n",
        "    - Debt ratios\n",
        "    - Aggregation theo CREDIT_ACTIVE\n",
        "    - Aggregation theo CREDIT_TYPE\n",
        "    \"\"\"\n",
        "    bureau = pd.read_csv(bureau_path)\n",
        "\n",
        "    # Clean extreme negative values\n",
        "    for col in ['DAYS_CREDIT_ENDDATE', 'DAYS_CREDIT_UPDATE', 'DAYS_ENDDATE_FACT']:\n",
        "        bureau.loc[bureau[col] < -40000, col] = np.nan\n",
        "\n",
        "    # Duration features\n",
        "    bureau['CREDIT_DURATION'] = bureau['DAYS_CREDIT'] - bureau['DAYS_CREDIT_ENDDATE']\n",
        "    bureau['ENDDATE_DIF'] = bureau['DAYS_CREDIT_ENDDATE'] - bureau['DAYS_ENDDATE_FACT']\n",
        "\n",
        "    # Debt & utilization ratios\n",
        "    bureau['DEBT_PERCENTAGE'] = safe_divide(\n",
        "        bureau['AMT_CREDIT_SUM'],\n",
        "        bureau['AMT_CREDIT_SUM_DEBT']\n",
        "    ).clip(-9, 9)\n",
        "\n",
        "    bureau['BUREAU_CREDIT_DEBT_RATIO'] = safe_divide(\n",
        "        bureau['AMT_CREDIT_SUM_DEBT'],\n",
        "        bureau['AMT_CREDIT_SUM']\n",
        "    ).clip(-9, 9)\n",
        "\n",
        "    bureau['CREDIT_TO_ANNUITY_RATIO'] = safe_divide(\n",
        "        bureau['AMT_CREDIT_SUM'],\n",
        "        bureau['AMT_ANNUITY']\n",
        "    ).clip(-9, 9)\n",
        "\n",
        "    bureau['UTILIZATION_RATIO'] = safe_divide(\n",
        "        bureau['AMT_CREDIT_SUM_DEBT'],\n",
        "        bureau['AMT_CREDIT_SUM_LIMIT']\n",
        "    ).clip(-9, 9)\n",
        "\n",
        "    bureau['DEBT_CREDIT_DIFF'] = bureau['AMT_CREDIT_SUM'] - bureau['AMT_CREDIT_SUM_DEBT']\n",
        "\n",
        "    # Time windows\n",
        "    bureau['LAST_30_DAYS'] = (bureau['DAYS_CREDIT'] >= -30).astype(int)\n",
        "    bureau['LAST_180_DAYS'] = (bureau['DAYS_CREDIT'] >= -180).astype(int)\n",
        "    bureau['LAST_365_DAYS'] = (bureau['DAYS_CREDIT'] >= -365).astype(int)\n",
        "    bureau['LAST_1095_DAYS'] = (bureau['DAYS_CREDIT'] >= -1095).astype(int)\n",
        "    bureau['LIFE_TIME_CREDIT'] = (bureau['DAYS_CREDIT_ENDDATE'] >= 16000).astype(int)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # GENERAL AGGREGATIONS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    general_agg = {\n",
        "        'SK_ID_BUREAU': 'count',\n",
        "        'AMT_CREDIT_SUM': ['sum', 'mean', 'std'],\n",
        "        'AMT_CREDIT_SUM_DEBT': ['sum', 'mean', 'std'],\n",
        "        'AMT_CREDIT_SUM_OVERDUE': ['sum', 'mean'],\n",
        "        'AMT_ANNUITY': ['sum', 'mean', 'std'],\n",
        "        'AMT_CREDIT_MAX_OVERDUE': ['sum', 'mean', 'std'],\n",
        "        'AMT_CREDIT_SUM_LIMIT': ['sum', 'mean', 'std'],\n",
        "        'DAYS_CREDIT': ['min', 'max', 'mean', 'std'],\n",
        "        'DAYS_CREDIT_UPDATE': ['mean', 'max'],\n",
        "        'CREDIT_DURATION': ['mean', 'std'],\n",
        "        'ENDDATE_DIF': 'mean',\n",
        "        'DEBT_PERCENTAGE': ['mean', 'std'],\n",
        "        'DEBT_CREDIT_DIFF': ['mean', 'std'],\n",
        "        'CREDIT_TO_ANNUITY_RATIO': ['mean', 'std'],\n",
        "        'BUREAU_CREDIT_DEBT_RATIO': ['mean', 'std'],\n",
        "        'UTILIZATION_RATIO': ['mean', 'std'],\n",
        "        'CREDIT_TYPE': 'nunique',\n",
        "        'CREDIT_ACTIVE': 'nunique',\n",
        "        'CNT_CREDIT_PROLONG': 'mean',\n",
        "    }\n",
        "\n",
        "    bureau_agg = bureau.groupby('SK_ID_CURR').agg(general_agg)\n",
        "    bureau_agg.columns = ['BUREAU_' + '_'.join(col).upper() for col in bureau_agg.columns]\n",
        "    bureau_agg = bureau_agg.reset_index()\n",
        "\n",
        "    # Derived feature\n",
        "    bureau_agg['BUREAU_AVG_PAST_LOAN_PER_TYPE'] = safe_divide(\n",
        "        bureau_agg['BUREAU_CREDIT_TYPE_NUNIQUE'],\n",
        "        bureau_agg['BUREAU_SK_ID_BUREAU_COUNT']\n",
        "    )\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # BY CREDIT_TYPE\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    credit_types = ['Car loan', 'Credit card', 'Mortgage', 'Consumer credit', 'Microloan']\n",
        "    for credit_type in credit_types:\n",
        "        type_df = bureau[bureau['CREDIT_TYPE'] == credit_type]\n",
        "        if len(type_df) > 0:\n",
        "            type_agg = type_df.groupby('SK_ID_CURR').agg({\n",
        "                'AMT_CREDIT_SUM': 'sum',\n",
        "                'AMT_CREDIT_SUM_DEBT': 'sum',\n",
        "                'AMT_CREDIT_SUM_OVERDUE': 'sum'\n",
        "            }).reset_index()\n",
        "\n",
        "            type_name = credit_type.replace(' ', '_').upper()\n",
        "            type_agg.columns = ['SK_ID_CURR',\n",
        "                               f'BUREAU_SUM_{type_name}',\n",
        "                               f'BUREAU_SUM_DEBT_{type_name}',\n",
        "                               f'BUREAU_SUM_OVERDUE_{type_name}']\n",
        "            bureau_agg = bureau_agg.merge(type_agg, on='SK_ID_CURR', how='left')\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # BY CREDIT_ACTIVE\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    # Active loans\n",
        "    active = bureau[bureau['CREDIT_ACTIVE'] == 'Active']\n",
        "    if len(active) > 0:\n",
        "        active_agg = active.groupby('SK_ID_CURR').agg({\n",
        "            'SK_ID_BUREAU': 'count',\n",
        "            'AMT_CREDIT_SUM': 'sum',\n",
        "            'AMT_CREDIT_SUM_DEBT': 'sum',\n",
        "            'LAST_30_DAYS': 'sum',\n",
        "            'LAST_180_DAYS': 'sum',\n",
        "            'LAST_365_DAYS': 'sum',\n",
        "            'LIFE_TIME_CREDIT': 'sum'\n",
        "        }).reset_index()\n",
        "        active_agg.columns = ['SK_ID_CURR', 'BUREAU_ACTIVE_COUNT',\n",
        "                             'BUREAU_ACTIVE_SUM_CREDIT', 'BUREAU_ACTIVE_SUM_DEBT',\n",
        "                             'BUREAU_ACTIVE_LAST_30D', 'BUREAU_ACTIVE_LAST_180D',\n",
        "                             'BUREAU_ACTIVE_LAST_365D', 'BUREAU_ACTIVE_LIFETIME']\n",
        "        bureau_agg = bureau_agg.merge(active_agg, on='SK_ID_CURR', how='left')\n",
        "\n",
        "    # Closed loans\n",
        "    closed = bureau[bureau['CREDIT_ACTIVE'] == 'Closed']\n",
        "    if len(closed) > 0:\n",
        "        closed['LATENCY'] = closed['DAYS_CREDIT_ENDDATE'] - closed['DAYS_ENDDATE_FACT']\n",
        "        closed_agg = closed.groupby('SK_ID_CURR').agg({\n",
        "            'SK_ID_BUREAU': 'count',\n",
        "            'AMT_CREDIT_SUM': 'sum',\n",
        "            'LATENCY': ['mean', 'sum'],\n",
        "            'LAST_365_DAYS': 'sum'\n",
        "        }).reset_index()\n",
        "        closed_agg.columns = ['SK_ID_CURR', 'BUREAU_CLOSED_COUNT',\n",
        "                             'BUREAU_CLOSED_SUM_CREDIT',\n",
        "                             'BUREAU_CLOSED_LATENCY_MEAN',\n",
        "                             'BUREAU_CLOSED_LATENCY_SUM',\n",
        "                             'BUREAU_CLOSED_LAST_365D']\n",
        "        bureau_agg = bureau_agg.merge(closed_agg, on='SK_ID_CURR', how='left')\n",
        "\n",
        "    # Bad debt\n",
        "    bad_debt = bureau[bureau['CREDIT_ACTIVE'] == 'Bad debt']\n",
        "    if len(bad_debt) > 0:\n",
        "        bad_agg = bad_debt.groupby('SK_ID_CURR').agg({\n",
        "            'SK_ID_BUREAU': 'count',\n",
        "            'AMT_CREDIT_SUM': 'sum'\n",
        "        }).reset_index()\n",
        "        bad_agg.columns = ['SK_ID_CURR', 'BUREAU_BAD_DEBT_COUNT', 'BUREAU_BAD_DEBT_SUM']\n",
        "        bureau_agg = bureau_agg.merge(bad_agg, on='SK_ID_CURR', how='left')\n",
        "\n",
        "    # Overall debt/credit ratio\n",
        "    bureau_agg['BUREAU_DEBT_CREDIT_RATIO'] = safe_divide(\n",
        "        bureau_agg['BUREAU_AMT_CREDIT_SUM_DEBT_SUM'],\n",
        "        bureau_agg['BUREAU_AMT_CREDIT_SUM_SUM']\n",
        "    )\n",
        "\n",
        "    # Merge bureau_balance if provided\n",
        "    if bureau_balance_path:\n",
        "        bb = pd.read_csv(bureau_balance_path)\n",
        "        bb_agg = process_bureau_balance(bb)\n",
        "        bureau = bureau.merge(bb_agg, on='SK_ID_BUREAU', how='left')\n",
        "        bb_curr_agg = bureau.groupby('SK_ID_CURR').agg({\n",
        "            'BB_MONTHS_COUNT': 'mean',\n",
        "            'BB_RATIO_NO_DPD': 'mean'\n",
        "        }).reset_index()\n",
        "        bb_curr_agg.columns = ['SK_ID_CURR', 'BUREAU_BB_MONTHS_AVG', 'BUREAU_BB_RATIO_NO_DPD_AVG']\n",
        "        bureau_agg = bureau_agg.merge(bb_curr_agg, on='SK_ID_CURR', how='left')\n",
        "\n",
        "    return bureau_agg"
      ],
      "metadata": {
        "id": "GZeKqEX07nun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 3. PREVIOUS_APPLICATION\n",
        "# ============================================================================\n",
        "\n",
        "def process_previous_application(prev_path: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Xử lý previous_application với:\n",
        "    - Category simplification\n",
        "    - Domain features (FINISH_RATE, ACTIVE, DURATION)\n",
        "    - Financial ratios\n",
        "    - Insurance features\n",
        "    - Aggregation: general, approved, refused\n",
        "    \"\"\"\n",
        "    prev = pd.read_csv(prev_path)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 3.1. CATEGORY CLEANING\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    # Goods category simplification\n",
        "    goods_to_other = ['Gardening', 'Animals', 'Insurance', 'Medicine', 'Fitness',\n",
        "                      'Direct Sales', 'Additional Service', 'Education', 'Weapon']\n",
        "    prev['NAME_GOODS_CATEGORY'] = prev['NAME_GOODS_CATEGORY'].replace(goods_to_other, 'Other')\n",
        "\n",
        "    # Cash loan purpose simplification\n",
        "    purpose_to_other = ['Refusal to name the goal', 'Money for a third person',\n",
        "                        'Buying a garage', 'Gasification / water supply',\n",
        "                        'Business development', 'Buying a holiday home / land']\n",
        "    prev['NAME_CASH_LOAN_PURPOSE'] = prev['NAME_CASH_LOAN_PURPOSE'].replace(purpose_to_other, 'Other')\n",
        "    prev['NAME_CASH_LOAN_PURPOSE'] = prev['NAME_CASH_LOAN_PURPOSE'].replace(\n",
        "        ['Buying a new car', 'Buying a used car'], 'Buying a car'\n",
        "    )\n",
        "\n",
        "    # Boolean mapping\n",
        "    prev['FLAG_LAST_APPL_PER_CONTRACT'] = prev['FLAG_LAST_APPL_PER_CONTRACT'].map({'Y': 1, 'N': 0})\n",
        "\n",
        "    # Type suite simplification\n",
        "    prev['NAME_TYPE_SUITE'] = prev['NAME_TYPE_SUITE'].replace({\n",
        "        'Children': 'Family',\n",
        "        'Spouse, partner': 'Family',\n",
        "        'Other_A': 'Other',\n",
        "        'Other_B': 'Other',\n",
        "        'Unaccompanied': 'Single'\n",
        "    })\n",
        "\n",
        "    # Yield group mapping\n",
        "    prev['NAME_YIELD_GROUP'] = prev['NAME_YIELD_GROUP'].replace({\n",
        "        'XNA': 0, 'low_action': 1, 'low_normal': 1, 'middle': 3, 'high': 4\n",
        "    }).fillna(0)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 3.2. DOMAIN FEATURES\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    # Time-based features\n",
        "    prev['ACTIVE'] = (prev['DAYS_LAST_DUE'] > 0).astype(int)\n",
        "    prev['ACTUAL_DURATION'] = prev['DAYS_LAST_DUE'] - prev['DAYS_FIRST_DUE']\n",
        "    prev['DURATION'] = prev['DAYS_TERMINATION'] - prev['DAYS_FIRST_DUE']\n",
        "    prev['LIFETIME_LOAN'] = (prev['DAYS_TERMINATION'] > 16000).astype(int)\n",
        "\n",
        "    # Finish rate (completion ratio)\n",
        "    prev['FINISH_RATE'] = safe_divide(\n",
        "        prev['ACTUAL_DURATION'],\n",
        "        prev['DURATION']\n",
        "    ) * (1 - prev['ACTIVE']) * (1 - prev['LIFETIME_LOAN'])\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 3.3. FINANCIAL RATIOS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    prev['AMT_DOWN_PAYMENT'] = prev['AMT_DOWN_PAYMENT'].fillna(0)\n",
        "\n",
        "    # Application vs credit\n",
        "    prev['APP_CREDIT_PERC'] = safe_divide(\n",
        "        prev['AMT_APPLICATION'],\n",
        "        prev['AMT_CREDIT']\n",
        "    )\n",
        "\n",
        "    # Down payment & goods ratios\n",
        "    prev['DOWN_PAYMENT_RATIO'] = safe_divide(\n",
        "        prev['AMT_DOWN_PAYMENT'],\n",
        "        prev['AMT_CREDIT']\n",
        "    )\n",
        "    prev['GOODS_PRICE_RATIO'] = safe_divide(\n",
        "        prev['AMT_GOODS_PRICE'],\n",
        "        prev['AMT_CREDIT']\n",
        "    )\n",
        "\n",
        "    # Credit to annuity\n",
        "    prev['CREDIT_ANNUITY_RATIO'] = safe_divide(\n",
        "        prev['AMT_CREDIT'],\n",
        "        prev['AMT_ANNUITY']\n",
        "    )\n",
        "    prev['RATIO_APPLICATION_TO_ANNUITY'] = safe_divide(\n",
        "        prev['AMT_APPLICATION'],\n",
        "        prev['AMT_ANNUITY']\n",
        "    )\n",
        "    prev['RATIO_GOODS_TO_ANNUITY'] = safe_divide(\n",
        "        prev['AMT_GOODS_PRICE'],\n",
        "        prev['AMT_ANNUITY']\n",
        "    )\n",
        "\n",
        "    # Credit vs goods\n",
        "    prev['CREDIT_DOWNPAYMENT'] = prev['AMT_GOODS_PRICE'] - prev['AMT_DOWN_PAYMENT']\n",
        "\n",
        "    # Difference tracking\n",
        "    prev['AMT_DIFF_PERCENT'] = safe_divide(\n",
        "        prev['AMT_CREDIT'] - prev['AMT_APPLICATION'],\n",
        "        prev['AMT_APPLICATION']\n",
        "    ) * 100\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 3.4. INSURANCE FEATURES\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    prev['Insuranced_amt_application'] = prev['AMT_APPLICATION'] * prev['NFLAG_INSURED_ON_APPROVAL']\n",
        "    prev['Insuranced_amt_credit'] = prev['AMT_CREDIT'] * prev['NFLAG_INSURED_ON_APPROVAL']\n",
        "    prev['HIGH_AMT_APPLICATION'] = (prev['AMT_APPLICATION'] > 100000).astype(int)\n",
        "    prev['HIGH_DOWN_PAYMENT'] = (prev['AMT_DOWN_PAYMENT'] > 10000).astype(int)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 3.5. INTEREST CALCULATION\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    prev['INTEREST'] = prev['CNT_PAYMENT'] * prev['AMT_ANNUITY'] - prev['AMT_CREDIT']\n",
        "    prev['INTEREST_RATE'] = safe_divide(\n",
        "        2 * 12 * prev['INTEREST'],\n",
        "        prev['AMT_CREDIT'] * (prev['CNT_PAYMENT'] + 1)\n",
        "    )\n",
        "    prev['INTEREST_SHARE'] = safe_divide(prev['INTEREST'], prev['AMT_CREDIT'])\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 3.6. CHURN & BEHAVIOR\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    prev['CHURN_PREV'] = (\n",
        "        prev['DAYS_LAST_DUE_1ST_VERSION'] - prev['DAYS_LAST_DUE']\n",
        "    ).apply(lambda x: 1 if x >= 0 else (0 if x < 0 else np.nan))\n",
        "\n",
        "    # Time simplification\n",
        "    prev['WEEKDAY_APPR_PROCESS_START'] = prev['WEEKDAY_APPR_PROCESS_START'].replace(\n",
        "        ['MONDAY', 'TUESDAY', 'WEDNESDAY', 'THURSDAY', 'FRIDAY'], 'WEEK_DAY'\n",
        "    ).replace(['SATURDAY', 'SUNDAY'], 'WEEKEND').fillna('WEEK_DAY')\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 3.7. AGGREGATIONS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    # General aggregation\n",
        "    general_agg = {\n",
        "        'AMT_ANNUITY': ['sum', 'min', 'max', 'mean', 'std'],\n",
        "        'AMT_APPLICATION': ['sum', 'mean', 'std'],\n",
        "        'AMT_CREDIT': ['sum', 'min', 'max', 'mean', 'std'],\n",
        "        'APP_CREDIT_PERC': ['mean', 'std'],\n",
        "        'AMT_DOWN_PAYMENT': ['sum', 'max', 'mean', 'std'],\n",
        "        'AMT_GOODS_PRICE': ['sum', 'min', 'max', 'mean'],\n",
        "        'CREDIT_ANNUITY_RATIO': ['mean', 'std'],\n",
        "        'DOWN_PAYMENT_RATIO': ['mean', 'std'],\n",
        "        'GOODS_PRICE_RATIO': ['mean', 'std'],\n",
        "        'DAYS_DECISION': ['min', 'max', 'mean'],\n",
        "        'CNT_PAYMENT': ['mean', 'sum'],\n",
        "        'HIGH_DOWN_PAYMENT': 'sum',\n",
        "        'RATIO_APPLICATION_TO_ANNUITY': ['mean', 'std'],\n",
        "        'RATIO_GOODS_TO_ANNUITY': ['mean', 'std'],\n",
        "        'INTEREST_RATE': ['mean', 'std'],\n",
        "        'INTEREST_SHARE': ['mean', 'std'],\n",
        "    }\n",
        "\n",
        "    prev_agg = prev.groupby('SK_ID_CURR').agg(general_agg)\n",
        "    prev_agg.columns = ['PREV_' + '_'.join(col).upper() for col in prev_agg.columns]\n",
        "    prev_agg = prev_agg.reset_index()\n",
        "\n",
        "    # Approved loans aggregation\n",
        "    approved = prev[prev['NAME_CONTRACT_STATUS'] == 'Approved']\n",
        "    if len(approved) > 0:\n",
        "        approved_agg = {\n",
        "            'AMT_ANNUITY': ['sum', 'mean', 'std'],\n",
        "            'AMT_APPLICATION': ['sum', 'mean'],\n",
        "            'AMT_CREDIT': ['sum', 'mean', 'std'],\n",
        "            'APP_CREDIT_PERC': ['mean', 'std'],\n",
        "            'AMT_DOWN_PAYMENT': ['sum', 'mean'],\n",
        "            'CREDIT_ANNUITY_RATIO': ['mean', 'std'],\n",
        "            'CREDIT_DOWNPAYMENT': ['sum', 'mean', 'std'],\n",
        "            'DOWN_PAYMENT_RATIO': ['mean', 'std', 'max'],\n",
        "            'NFLAG_INSURED_ON_APPROVAL': 'sum',\n",
        "            'Insuranced_amt_application': ['sum', 'mean'],\n",
        "            'Insuranced_amt_credit': ['sum', 'mean'],\n",
        "            'DAYS_DECISION': 'max',\n",
        "            'CNT_PAYMENT': ['mean', 'sum'],\n",
        "            'ACTIVE': 'mean',\n",
        "            'DURATION': ['sum', 'max', 'min', 'mean', 'std'],\n",
        "            'ACTUAL_DURATION': ['sum', 'max', 'mean', 'std'],\n",
        "            'LIFETIME_LOAN': ['sum', 'mean'],\n",
        "            'FINISH_RATE': ['mean', 'std'],\n",
        "        }\n",
        "\n",
        "        app_agg = approved.groupby('SK_ID_CURR').agg(approved_agg)\n",
        "        app_agg.columns = ['APPROVED_' + '_'.join(col).upper() for col in app_agg.columns]\n",
        "        app_agg = app_agg.reset_index()\n",
        "\n",
        "        # Insurance ratios\n",
        "        app_agg['APPROVED_RATIO_AMT_APPLICATION_INSURANCED'] = safe_divide(\n",
        "            app_agg['APPROVED_INSURANCED_AMT_APPLICATION_SUM'],\n",
        "            app_agg['APPROVED_AMT_APPLICATION_SUM']\n",
        "        )\n",
        "        app_agg['APPROVED_RATIO_AMT_CREDIT_INSURANCED'] = safe_divide(\n",
        "            app_agg['APPROVED_INSURANCED_AMT_CREDIT_SUM'],\n",
        "            app_agg['APPROVED_AMT_CREDIT_SUM']\n",
        "        )\n",
        "\n",
        "        prev_agg = prev_agg.merge(app_agg, on='SK_ID_CURR', how='left')\n",
        "\n",
        "    # Refused loans aggregation\n",
        "    refused = prev[prev['NAME_CONTRACT_STATUS'] == 'Refused']\n",
        "    if len(refused) > 0:\n",
        "        refused_agg = {\n",
        "            'AMT_ANNUITY': ['sum', 'mean'],\n",
        "            'AMT_APPLICATION': ['sum', 'mean'],\n",
        "            'AMT_CREDIT': ['sum', 'mean'],\n",
        "            'APP_CREDIT_PERC': 'mean',\n",
        "            'AMT_DOWN_PAYMENT': ['sum', 'mean'],\n",
        "            'CREDIT_ANNUITY_RATIO': 'mean',\n",
        "            'DAYS_DECISION': ['max', 'mean'],\n",
        "        }\n",
        "\n",
        "        ref_agg = refused.groupby('SK_ID_CURR').agg(refused_agg)\n",
        "        ref_agg.columns = ['REFUSED_' + '_'.join(col).upper() for col in ref_agg.columns]\n",
        "        ref_agg = ref_agg.reset_index()\n",
        "\n",
        "        prev_agg = prev_agg.merge(ref_agg, on='SK_ID_CURR', how='left')\n",
        "\n",
        "    # Time-based features (last N applications)\n",
        "    prev_sorted = prev.sort_values(['SK_ID_CURR', 'DAYS_DECISION'])\n",
        "\n",
        "    # Number of previous applications\n",
        "    prev_count = prev_sorted.groupby('SK_ID_CURR')['SK_ID_PREV'].count().reset_index()\n",
        "    prev_count.columns = ['SK_ID_CURR', 'PREV_APPLICATION_COUNT']\n",
        "    prev_agg = prev_agg.merge(prev_count, on='SK_ID_CURR', how='left')\n",
        "\n",
        "    # Last application was approved/refused\n",
        "    prev_sorted['PREV_WAS_APPROVED'] = (prev_sorted['NAME_CONTRACT_STATUS'] == 'Approved').astype(int)\n",
        "    prev_sorted['PREV_WAS_REFUSED'] = (prev_sorted['NAME_CONTRACT_STATUS'] == 'Refused').astype(int)\n",
        "\n",
        "    last_status = prev_sorted.groupby('SK_ID_CURR').agg({\n",
        "        'PREV_WAS_APPROVED': 'last',\n",
        "        'PREV_WAS_REFUSED': 'last'\n",
        "    }).reset_index()\n",
        "    last_status.columns = ['SK_ID_CURR', 'PREV_LAST_WAS_APPROVED', 'PREV_LAST_WAS_REFUSED']\n",
        "    prev_agg = prev_agg.merge(last_status, on='SK_ID_CURR', how='left')\n",
        "\n",
        "    # Last N applications features\n",
        "    for n in [1, 3, 5]:\n",
        "        tail = prev_sorted.groupby('SK_ID_CURR').tail(n)\n",
        "        tail_agg = tail.groupby('SK_ID_CURR').agg({\n",
        "            'CNT_PAYMENT': 'mean',\n",
        "            'DAYS_DECISION': 'mean',\n",
        "            'DAYS_FIRST_DRAWING': 'mean'\n",
        "        }).reset_index()\n",
        "        tail_agg.columns = ['SK_ID_CURR',\n",
        "                           f'PREV_LAST_{n}_CNT_PAYMENT_MEAN',\n",
        "                           f'PREV_LAST_{n}_DAYS_DECISION_MEAN',\n",
        "                           f'PREV_LAST_{n}_DAYS_FIRST_DRAWING_MEAN']\n",
        "        prev_agg = prev_agg.merge(tail_agg, on='SK_ID_CURR', how='left')\n",
        "\n",
        "    return prev_agg"
      ],
      "metadata": {
        "id": "hzRtTYJz7rg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 4. POS_CASH_BALANCE\n",
        "# ============================================================================\n",
        "\n",
        "def process_pos_cash(pos_path: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Xử lý POS_CASH_balance với:\n",
        "    - Status flags\n",
        "    - DPD tracking\n",
        "    - Time windows\n",
        "    - Long/short term separation\n",
        "    \"\"\"\n",
        "    pos = pd.read_csv(pos_path)\n",
        "\n",
        "    # Remove invalid statuses\n",
        "    pos = pos[~pos['NAME_CONTRACT_STATUS'].isin(['XNA', 'Canceled'])]\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 4.1. STATUS FLAGS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    pos['COMPLETED'] = (pos['NAME_CONTRACT_STATUS'] == 'Completed').astype(int)\n",
        "    pos['COUNT_DEMAND'] = (pos['NAME_CONTRACT_STATUS'] == 'Demand').astype(int)\n",
        "    pos['COUNT_SIGNED'] = (pos['NAME_CONTRACT_STATUS'] == 'Signed').astype(int)\n",
        "    pos['COUNT_APPROVED'] = (pos['NAME_CONTRACT_STATUS'] == 'Approved').astype(int)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 4.2. DPD FEATURES\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    pos['COUNT_SK_DPD'] = (pos['SK_DPD'] > 0).astype(int)\n",
        "    pos['COUNT_SK_DPD_DEF'] = (pos['SK_DPD_DEF'] > 0).astype(int)\n",
        "    pos['MEAN_SK_DPD'] = pos['SK_DPD']\n",
        "    pos['MEAN_SK_DPD_DEF'] = pos['SK_DPD_DEF']\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 4.3. TIME WINDOWS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    pos['LAST_3_MONTHS'] = (pos['MONTHS_BALANCE'] >= -3).astype(int)\n",
        "    pos['LAST_6_MONTHS'] = (pos['MONTHS_BALANCE'] >= -6).astype(int)\n",
        "    pos['LAST_12_MONTHS'] = (pos['MONTHS_BALANCE'] >= -12).astype(int)\n",
        "    pos['LAST_36_MONTHS'] = (pos['MONTHS_BALANCE'] >= -36).astype(int)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 4.4. AGGREGATION PER SK_ID_PREV\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    pos['NUM_INSTALMENT'] = 1\n",
        "\n",
        "    pos_prev_agg = pos.groupby('SK_ID_PREV').agg({\n",
        "        'SK_ID_CURR': 'first',\n",
        "        'NUM_INSTALMENT': 'sum',\n",
        "        'COMPLETED': 'sum',\n",
        "        'COUNT_DEMAND': 'sum',\n",
        "        'COUNT_SIGNED': 'sum',\n",
        "        'CNT_INSTALMENT': 'max',\n",
        "        'MONTHS_BALANCE': 'max',\n",
        "        'COUNT_SK_DPD': 'sum',\n",
        "        'COUNT_SK_DPD_DEF': 'sum',\n",
        "        'SK_DPD': 'sum',\n",
        "        'SK_DPD_DEF': 'sum',\n",
        "        'MEAN_SK_DPD': 'mean',\n",
        "        'MEAN_SK_DPD_DEF': 'mean',\n",
        "        'CNT_INSTALMENT_FUTURE': 'min',\n",
        "        'LAST_12_MONTHS': 'sum',\n",
        "        'LAST_36_MONTHS': 'sum'\n",
        "    }).reset_index()\n",
        "\n",
        "    # Long term vs short term\n",
        "    pos_prev_agg['LONG_TERM'] = (pos_prev_agg['CNT_INSTALMENT'] > 24).astype(int)\n",
        "    pos_prev_agg['SHORT_TERM'] = (pos_prev_agg['CNT_INSTALMENT'] <= 24).astype(int)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 4.5. AGGREGATION PER SK_ID_CURR\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    # General aggregation\n",
        "    pos_agg = pos_prev_agg.groupby('SK_ID_CURR').agg({\n",
        "        'NUM_INSTALMENT': 'sum',\n",
        "        'COMPLETED': ['sum', 'mean'],\n",
        "        'COUNT_SIGNED': 'sum',\n",
        "        'CNT_INSTALMENT': ['sum', 'mean', 'std'],\n",
        "        'MONTHS_BALANCE': 'max',\n",
        "        'SK_DPD': ['sum', 'mean', 'max'],\n",
        "        'SK_DPD_DEF': ['sum', 'mean', 'max'],\n",
        "        'COUNT_SK_DPD': ['sum', 'mean'],\n",
        "        'COUNT_SK_DPD_DEF': ['sum', 'mean'],\n",
        "        'CNT_INSTALMENT_FUTURE': 'sum',\n",
        "        'LAST_12_MONTHS': 'sum',\n",
        "        'LAST_36_MONTHS': 'sum'\n",
        "    })\n",
        "\n",
        "    # Flatten column names\n",
        "    pos_agg.columns = ['POS_' + '_'.join(col).upper() for col in pos_agg.columns]\n",
        "    pos_agg = pos_agg.reset_index()\n",
        "\n",
        "    # Completion ratio\n",
        "    pos_agg['POS_COMPLETION_RATIO'] = safe_divide(\n",
        "        pos_agg['POS_COMPLETED_SUM'],\n",
        "        pos_agg['POS_NUM_INSTALMENT_SUM']\n",
        "    )\n",
        "\n",
        "    # Long-term contracts\n",
        "    long_term = pos_prev_agg[pos_prev_agg['LONG_TERM'] == 1]\n",
        "    if len(long_term) > 0:\n",
        "        lt_agg = long_term.groupby('SK_ID_CURR').agg({\n",
        "            'CNT_INSTALMENT': 'mean',\n",
        "            'SK_ID_PREV': 'count',\n",
        "            'NUM_INSTALMENT': 'sum',\n",
        "            'LAST_36_MONTHS': 'sum'\n",
        "        }).reset_index()\n",
        "        lt_agg.columns = ['SK_ID_CURR', 'POS_LONG_TERM_CNT_INSTALMENT_MEAN',\n",
        "                         'POS_LONG_TERM_COUNT', 'POS_LONG_TERM_NUM_INSTALMENT',\n",
        "                         'POS_LONG_TERM_LAST_36M']\n",
        "        pos_agg = pos_agg.merge(lt_agg, on='SK_ID_CURR', how='left')\n",
        "\n",
        "    # Short-term contracts\n",
        "    short_term = pos_prev_agg[pos_prev_agg['SHORT_TERM'] == 1]\n",
        "    if len(short_term) > 0:\n",
        "        st_agg = short_term.groupby('SK_ID_CURR').agg({\n",
        "            'CNT_INSTALMENT': 'mean',\n",
        "            'SK_ID_PREV': 'count',\n",
        "            'NUM_INSTALMENT': 'sum',\n",
        "            'LAST_12_MONTHS': 'sum',\n",
        "            'SK_DPD': 'sum'\n",
        "        }).reset_index()\n",
        "        st_agg.columns = ['SK_ID_CURR', 'POS_SHORT_TERM_CNT_INSTALMENT_MEAN',\n",
        "                         'POS_SHORT_TERM_COUNT', 'POS_SHORT_TERM_NUM_INSTALMENT',\n",
        "                         'POS_SHORT_TERM_LAST_12M', 'POS_SHORT_TERM_SK_DPD']\n",
        "        pos_agg = pos_agg.merge(st_agg, on='SK_ID_CURR', how='left')\n",
        "\n",
        "    return pos_agg\n",
        "\n"
      ],
      "metadata": {
        "id": "LYdGzZBf7reX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 5. INSTALLMENTS_PAYMENTS\n",
        "# ============================================================================\n",
        "\n",
        "def process_installments(inst_path: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Xử lý installments_payments với:\n",
        "    - Payment difference tracking\n",
        "    - Late/early payment analysis\n",
        "    - Time window aggregations\n",
        "    \"\"\"\n",
        "    inst = pd.read_csv(inst_path)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 5.1. ROW-LEVEL FEATURES\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    inst['INSTALLMENT_PAYMENT_DIFF'] = inst['AMT_INSTALMENT'] - inst['AMT_PAYMENT']\n",
        "    inst['DIFF'] = inst['DAYS_INSTALMENT'] - inst['DAYS_ENTRY_PAYMENT']\n",
        "\n",
        "    # Late/early indicators\n",
        "    inst['LATE'] = inst['DIFF'].clip(lower=0)\n",
        "    inst['EARLY'] = (-inst['DIFF']).clip(lower=0)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 5.2. TIME WINDOWS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    for days in [30, 60, 90, 180, 365, 730]:\n",
        "        inst[f'LAST_{days}_DAYS'] = (inst['DAYS_ENTRY_PAYMENT'] >= -days).astype(int)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 5.3. WEIGHTED FEATURES BY TIME WINDOW\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    for days in [30, 90, 180, 365, 730]:\n",
        "        inst[f'PAYMENT_LAST_{days}_DAYS'] = inst[f'LAST_{days}_DAYS'] * inst['AMT_PAYMENT']\n",
        "        inst[f'LATENESS_LAST_{days}_DAYS'] = inst[f'LAST_{days}_DAYS'] * inst['LATE']\n",
        "        inst[f'EARLYNESS_LAST_{days}_DAYS'] = inst[f'LAST_{days}_DAYS'] * inst['EARLY']\n",
        "        inst[f'INSTALLMENT_PAYMENT_DIFF_LAST_{days}_DAYS'] = (\n",
        "            inst[f'LAST_{days}_DAYS'] * inst['INSTALLMENT_PAYMENT_DIFF']\n",
        "        )\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 5.4. AGGREGATION PER SK_ID_CURR\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    inst_agg_dict = {\n",
        "        'NUM_INSTALMENT_NUMBER': 'max',\n",
        "        'SK_ID_PREV': 'nunique',\n",
        "        'DIFF': ['sum', 'mean', 'std'],\n",
        "        'LATE': ['sum', 'mean', 'std', 'max'],\n",
        "        'EARLY': ['sum', 'mean', 'std'],\n",
        "        'DAYS_ENTRY_PAYMENT': 'max',\n",
        "        'INSTALLMENT_PAYMENT_DIFF': ['sum', 'mean', 'std'],\n",
        "        'AMT_PAYMENT': 'sum',\n",
        "    }\n",
        "\n",
        "    # Add time window features\n",
        "    for days in [30, 90, 180, 365, 730]:\n",
        "        inst_agg_dict[f'LAST_{days}_DAYS'] = 'sum'\n",
        "        inst_agg_dict[f'PAYMENT_LAST_{days}_DAYS'] = ['sum', 'mean', 'std']\n",
        "        inst_agg_dict[f'LATENESS_LAST_{days}_DAYS'] = ['sum', 'mean']\n",
        "        inst_agg_dict[f'EARLYNESS_LAST_{days}_DAYS'] = ['sum', 'mean']\n",
        "        inst_agg_dict[f'INSTALLMENT_PAYMENT_DIFF_LAST_{days}_DAYS'] = ['sum', 'mean']\n",
        "\n",
        "    inst_agg = inst.groupby('SK_ID_CURR').agg(inst_agg_dict)\n",
        "\n",
        "    # Flatten column names properly\n",
        "    new_cols = []\n",
        "    for col in inst_agg.columns:\n",
        "        if isinstance(col, tuple):\n",
        "            new_cols.append('INST_' + '_'.join(str(x).upper() for x in col))\n",
        "        else:\n",
        "            new_cols.append('INST_' + str(col).upper())\n",
        "\n",
        "    inst_agg.columns = new_cols\n",
        "    inst_agg = inst_agg.reset_index()\n",
        "\n",
        "    # Average installment amount\n",
        "    inst_agg['INST_AVG_PAYMENT_PER_INSTALMENT'] = safe_divide(\n",
        "        inst_agg['INST_AMT_PAYMENT_SUM'],\n",
        "        inst_agg['INST_NUM_INSTALMENT_NUMBER_MAX']\n",
        "    )\n",
        "\n",
        "    # Late payment rate\n",
        "    inst_agg['INST_LATE_PAYMENT_RATE'] = safe_divide(\n",
        "        inst_agg['INST_LATE_SUM'],\n",
        "        inst_agg['INST_NUM_INSTALMENT_NUMBER_MAX']\n",
        "    )\n",
        "\n",
        "    return inst_agg\n"
      ],
      "metadata": {
        "id": "MXqK874r7rbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 6. CREDIT_CARD_BALANCE\n",
        "# ============================================================================\n",
        "\n",
        "def process_credit_card(cc_path: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Xử lý credit_card_balance với:\n",
        "    - Utilization tracking\n",
        "    - Payment behavior\n",
        "    - Drawing patterns\n",
        "    - Time window analysis\n",
        "    \"\"\"\n",
        "    cc = pd.read_csv(cc_path)\n",
        "\n",
        "    # Clean negative values\n",
        "    cc.loc[cc['AMT_DRAWINGS_ATM_CURRENT'] < 0, 'AMT_DRAWINGS_ATM_CURRENT'] = np.nan\n",
        "    cc.loc[cc['AMT_DRAWINGS_CURRENT'] < 0, 'AMT_DRAWINGS_CURRENT'] = np.nan\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 6.1. STATUS FLAGS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    cc['ACTIVE'] = (cc['NAME_CONTRACT_STATUS'] == 'Active').astype(int)\n",
        "    cc['COMPLETED'] = (cc['NAME_CONTRACT_STATUS'] == 'Completed').astype(int)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 6.2. UTILIZATION & PAYMENT BEHAVIOR\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    cc['UTILIZATION'] = safe_divide(\n",
        "        cc['AMT_BALANCE'],\n",
        "        cc['AMT_CREDIT_LIMIT_ACTUAL']\n",
        "    ).clip(-9, 9)\n",
        "\n",
        "    cc['RATE_OF_PAYBACK'] = safe_divide(\n",
        "        cc['AMT_PAYMENT_TOTAL_CURRENT'],\n",
        "        cc['AMT_INST_MIN_REGULARITY']\n",
        "    ).clip(-9, 9)\n",
        "\n",
        "    cc['PERCENTAGE_OF_MINIMUM_PAYMENTS_MISSED'] = safe_divide(\n",
        "        cc['AMT_PAYMENT_CURRENT'],\n",
        "        cc['AMT_INST_MIN_REGULARITY']\n",
        "    ).clip(-9, 9)\n",
        "\n",
        "    cc['MINIMUM_PAYMENTS_ONLY'] = (\n",
        "        cc['AMT_PAYMENT_CURRENT'] == cc['AMT_INST_MIN_REGULARITY']\n",
        "    ).astype(int)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 6.3. DRAWING BEHAVIOR\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    cc['SUM_ALL_CNT_DRAWINGS'] = (\n",
        "        cc['CNT_DRAWINGS_ATM_CURRENT'] +\n",
        "        cc['CNT_DRAWINGS_CURRENT'] +\n",
        "        cc['CNT_DRAWINGS_OTHER_CURRENT'] +\n",
        "        cc['CNT_DRAWINGS_POS_CURRENT']\n",
        "    )\n",
        "\n",
        "    cc['SUM_ALL_AMT_DRAWINGS'] = (\n",
        "        cc['AMT_DRAWINGS_ATM_CURRENT'].fillna(0) +\n",
        "        cc['AMT_DRAWINGS_CURRENT'].fillna(0) +\n",
        "        cc['AMT_DRAWINGS_OTHER_CURRENT'].fillna(0) +\n",
        "        cc['AMT_DRAWINGS_POS_CURRENT'].fillna(0)\n",
        "    )\n",
        "\n",
        "    cc['RATIO_ALL_AMT_DRAWINGS_TO_ALL_CNT_DRAWINGS'] = safe_divide(\n",
        "        cc['SUM_ALL_AMT_DRAWINGS'],\n",
        "        cc['SUM_ALL_CNT_DRAWINGS']\n",
        "    ).clip(-9, 9)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 6.4. FLAGS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    cc['POSITIVE_CREDIT'] = (cc['AMT_BALANCE'] > 0).astype(int)\n",
        "    cc['FLAG_UTILIZATION_LESS_50'] = (cc['UTILIZATION'] < 0.50).astype(int)\n",
        "    cc['FLAG_UTILIZATION_LESS_75'] = (cc['UTILIZATION'] < 0.75).astype(int)\n",
        "    cc['FLAG_UTILIZATION_MORE_100'] = (cc['UTILIZATION'] > 1.00).astype(int)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 6.5. TIME WINDOWS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    for months in [6, 12, 36]:\n",
        "        cc[f'FLAG_{months}_MONTHS'] = (cc['MONTHS_BALANCE'] >= -months).astype(int)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 6.6. AGGREGATIONS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    # General aggregation\n",
        "    cc_agg_dict = {\n",
        "        'MONTHS_BALANCE': 'count',\n",
        "        'ACTIVE': 'sum',\n",
        "        'AMT_BALANCE': 'sum',\n",
        "        'AMT_CREDIT_LIMIT_ACTUAL': ['mean', 'max', 'min', 'std'],\n",
        "        'AMT_INST_MIN_REGULARITY': ['mean', 'max', 'std'],\n",
        "        'AMT_PAYMENT_TOTAL_CURRENT': ['sum', 'mean', 'max', 'min', 'std'],\n",
        "        'UTILIZATION': 'sum',\n",
        "        'FLAG_UTILIZATION_LESS_50': ['sum', 'mean'],\n",
        "        'FLAG_UTILIZATION_LESS_75': ['sum', 'mean'],\n",
        "        'FLAG_UTILIZATION_MORE_100': ['sum', 'mean'],\n",
        "        'CNT_DRAWINGS_ATM_CURRENT': ['mean', 'sum'],\n",
        "        'CNT_DRAWINGS_CURRENT': ['mean', 'sum'],\n",
        "        'AMT_DRAWINGS_ATM_CURRENT': ['sum', 'mean', 'std'],\n",
        "        'AMT_DRAWINGS_CURRENT': ['sum', 'mean', 'max', 'std'],\n",
        "        'AMT_DRAWINGS_POS_CURRENT': ['sum', 'mean', 'std'],\n",
        "        'POSITIVE_CREDIT': 'sum',\n",
        "        'MINIMUM_PAYMENTS_ONLY': 'sum',\n",
        "        'SUM_ALL_CNT_DRAWINGS': ['sum', 'mean'],\n",
        "        'SUM_ALL_AMT_DRAWINGS': ['sum', 'mean'],\n",
        "        'RATIO_ALL_AMT_DRAWINGS_TO_ALL_CNT_DRAWINGS': ['mean', 'std'],\n",
        "        'RATE_OF_PAYBACK': 'sum',\n",
        "        'PERCENTAGE_OF_MINIMUM_PAYMENTS_MISSED': 'sum',\n",
        "    }\n",
        "\n",
        "    cc_agg = cc.groupby('SK_ID_CURR').agg(cc_agg_dict)\n",
        "\n",
        "    # Flatten column names\n",
        "    cc_agg.columns = ['CC_' + '_'.join(col).upper() for col in cc_agg.columns]\n",
        "    cc_agg = cc_agg.reset_index()\n",
        "\n",
        "    # Normalize by positive credit months\n",
        "    cc_agg['CC_AMT_BALANCE_AVG'] = safe_divide(\n",
        "        cc_agg['CC_AMT_BALANCE_SUM'],\n",
        "        cc_agg['CC_POSITIVE_CREDIT_SUM']\n",
        "    )\n",
        "    cc_agg['CC_UTILIZATION_AVG'] = safe_divide(\n",
        "        cc_agg['CC_UTILIZATION_SUM'],\n",
        "        cc_agg['CC_POSITIVE_CREDIT_SUM']\n",
        "    )\n",
        "    cc_agg['CC_POSITIVE_PERCENT'] = safe_divide(\n",
        "        cc_agg['CC_POSITIVE_CREDIT_SUM'],\n",
        "        cc_agg['CC_MONTHS_BALANCE_COUNT']\n",
        "    )\n",
        "\n",
        "    # Time window aggregations\n",
        "    for months in [6, 12, 36]:\n",
        "        window_df = cc[cc[f'FLAG_{months}_MONTHS'] == 1]\n",
        "        if len(window_df) > 0:\n",
        "            window_agg = window_df.groupby('SK_ID_CURR').agg({\n",
        "                'AMT_BALANCE': 'sum',\n",
        "                'AMT_CREDIT_LIMIT_ACTUAL': ['mean', 'std'],\n",
        "                'AMT_PAYMENT_TOTAL_CURRENT': 'sum',\n",
        "                'UTILIZATION': 'sum',\n",
        "                'CNT_DRAWINGS_CURRENT': 'sum',\n",
        "                'AMT_DRAWINGS_CURRENT': ['sum', 'max'],\n",
        "                'POSITIVE_CREDIT': 'sum'\n",
        "            })\n",
        "\n",
        "            # Flatten columns\n",
        "            window_agg.columns = [f'CC_{months}M_' + '_'.join(col).upper()\n",
        "                                 for col in window_agg.columns]\n",
        "            window_agg = window_agg.reset_index()\n",
        "\n",
        "            # Normalize\n",
        "            window_agg[f'CC_{months}M_AMT_BALANCE_AVG'] = safe_divide(\n",
        "                window_agg[f'CC_{months}M_AMT_BALANCE_SUM'],\n",
        "                window_agg[f'CC_{months}M_POSITIVE_CREDIT_SUM']\n",
        "            )\n",
        "            window_agg[f'CC_{months}M_UTILIZATION_AVG'] = safe_divide(\n",
        "                window_agg[f'CC_{months}M_UTILIZATION_SUM'],\n",
        "                window_agg[f'CC_{months}M_POSITIVE_CREDIT_SUM']\n",
        "            )\n",
        "\n",
        "            cc_agg = cc_agg.merge(window_agg, on='SK_ID_CURR', how='left')\n",
        "\n",
        "    return cc_agg\n"
      ],
      "metadata": {
        "id": "QiYpk1Bw7rZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 7. MAIN PIPELINE - MERGE ALL\n",
        "# ============================================================================\n",
        "\n",
        "def feature_engineering_pipeline(\n",
        "    app_train_path: str,\n",
        "    app_test_path: str,\n",
        "    bureau_path: str,\n",
        "    bureau_balance_path: str,\n",
        "    prev_path: str,\n",
        "    pos_path: str,\n",
        "    inst_path: str,\n",
        "    cc_path: str,\n",
        "    output_dir: str\n",
        ") -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series]:\n",
        "    \"\"\"\n",
        "    Pipeline tổng thể:\n",
        "    1. Load và process từng bảng\n",
        "    2. Merge theo thứ tự\n",
        "    3. Xử lý NaN\n",
        "    4. Export X_train_fe, X_test_fe\n",
        "    \"\"\"\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 7.1. LOAD & PROCESS APPLICATION\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    print(\"\\n[1/8] Processing application_train...\")\n",
        "    app_train = pd.read_csv(app_train_path)\n",
        "    app_train_fe = process_application(app_train)\n",
        "    y_train = app_train_fe['TARGET']\n",
        "    print(f\"  Shape: {app_train_fe.shape}\")\n",
        "\n",
        "    print(\"\\n[2/8] Processing application_test...\")\n",
        "    app_test = pd.read_csv(app_test_path)\n",
        "    app_test_fe = process_application(app_test)\n",
        "    print(f\"  Shape: {app_test_fe.shape}\")\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 7.2. PROCESS AUXILIARY TABLES\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    print(\"\\n[3/8] Processing bureau + bureau_balance...\")\n",
        "    bureau_agg = process_bureau(bureau_path, bureau_balance_path)\n",
        "    print(f\"  Shape: {bureau_agg.shape}\")\n",
        "\n",
        "    print(\"\\n[4/8] Processing previous_application...\")\n",
        "    prev_agg = process_previous_application(prev_path)\n",
        "    print(f\"  Shape: {prev_agg.shape}\")\n",
        "\n",
        "    print(\"\\n[5/8] Processing POS_CASH_balance...\")\n",
        "    pos_agg = process_pos_cash(pos_path)\n",
        "    print(f\"  Shape: {pos_agg.shape}\")\n",
        "\n",
        "    print(\"\\n[6/8] Processing installments_payments...\")\n",
        "    inst_agg = process_installments(inst_path)\n",
        "    print(f\"  Shape: {inst_agg.shape}\")\n",
        "\n",
        "    print(\"\\n[7/8] Processing credit_card_balance...\")\n",
        "    cc_agg = process_credit_card(cc_path)\n",
        "    print(f\"  Shape: {cc_agg.shape}\")\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 7.3. MERGE ALL - LEFT JOIN\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    print(\"\\n[8/8] Merging all tables...\")\n",
        "\n",
        "    # Merge train\n",
        "    print(\"  Merging train dataset...\")\n",
        "    X_train_fe = app_train_fe.copy()\n",
        "    X_train_fe = X_train_fe.merge(bureau_agg, on='SK_ID_CURR', how='left')\n",
        "    print(f\"    After bureau: {X_train_fe.shape}\")\n",
        "\n",
        "    X_train_fe = X_train_fe.merge(prev_agg, on='SK_ID_CURR', how='left')\n",
        "    print(f\"    After previous: {X_train_fe.shape}\")\n",
        "\n",
        "    X_train_fe = X_train_fe.merge(pos_agg, on='SK_ID_CURR', how='left')\n",
        "    print(f\"    After POS: {X_train_fe.shape}\")\n",
        "\n",
        "    X_train_fe = X_train_fe.merge(inst_agg, on='SK_ID_CURR', how='left')\n",
        "    print(f\"    After installments: {X_train_fe.shape}\")\n",
        "\n",
        "    X_train_fe = X_train_fe.merge(cc_agg, on='SK_ID_CURR', how='left')\n",
        "    print(f\"    After credit card: {X_train_fe.shape}\")\n",
        "\n",
        "    # Merge test\n",
        "    print(\"  Merging test dataset...\")\n",
        "    X_test_fe = app_test_fe.copy()\n",
        "    X_test_fe = X_test_fe.merge(bureau_agg, on='SK_ID_CURR', how='left')\n",
        "    X_test_fe = X_test_fe.merge(prev_agg, on='SK_ID_CURR', how='left')\n",
        "    X_test_fe = X_test_fe.merge(pos_agg, on='SK_ID_CURR', how='left')\n",
        "    X_test_fe = X_test_fe.merge(inst_agg, on='SK_ID_CURR', how='left')\n",
        "    X_test_fe = X_test_fe.merge(cc_agg, on='SK_ID_CURR', how='left')\n",
        "    print(f\"    Test shape: {X_test_fe.shape}\")\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 7.4. NaN HANDLING\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    print(\"\\n[Post-processing] Handling missing values...\")\n",
        "\n",
        "    # Drop TARGET from train features\n",
        "    X_train_fe = X_train_fe.drop(columns=['TARGET'])\n",
        "    app_cols = set(app_train.columns) - {'TARGET'}\n",
        "    auxiliary_cols = [col for col in X_train_fe.columns\n",
        "                     if col not in app_cols and col != 'SK_ID_CURR']\n",
        "\n",
        "    print(f\"  Filling {len(auxiliary_cols)} auxiliary columns with 0...\")\n",
        "    for col in auxiliary_cols:\n",
        "        X_train_fe[col] = X_train_fe[col].fillna(0)\n",
        "        X_test_fe[col] = X_test_fe[col].fillna(0)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 7.5. EXPORT\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    print(\"\\n[Export] Saving files...\")\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    train_path = os.path.join(output_dir, 'X_train_fe.parquet')\n",
        "    test_path = os.path.join(output_dir, 'X_test_fe.parquet')\n",
        "    target_path = os.path.join(output_dir, 'y_train.parquet')\n",
        "\n",
        "    X_train_fe.to_parquet(train_path, index=False)\n",
        "    X_test_fe.to_parquet(test_path, index=False)\n",
        "    y_train.to_frame('TARGET').to_parquet(target_path, index=False)\n",
        "\n",
        "    print(f\"  Saved: {train_path}\")\n",
        "    print(f\"  Saved: {test_path}\")\n",
        "    print(f\"  Saved: {target_path}\")\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 7.6. SUMMARY\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    print(\"FEATURE ENGINEERING COMPLETED\")\n",
        "    print(f\"Training set:  {X_train_fe.shape[0]:,} rows × {X_train_fe.shape[1]:,} features\")\n",
        "    print(f\"Test set:      {X_test_fe.shape[0]:,} rows × {X_test_fe.shape[1]:,} features\")\n",
        "    print(f\"Target:        {y_train.shape[0]:,} samples\")\n",
        "    print(f\"Target rate:   {y_train.mean():.2%}\")\n",
        "\n",
        "    # Feature type summary\n",
        "    numeric_cols = X_train_fe.select_dtypes(include=[np.number]).columns\n",
        "    categorical_cols = X_train_fe.select_dtypes(exclude=[np.number]).columns\n",
        "\n",
        "    print(f\"\\nFeature types:\")\n",
        "    print(f\"  Numeric:      {len(numeric_cols):,}\")\n",
        "    print(f\"  Categorical:  {len(categorical_cols):,}\")\n",
        "\n",
        "    # NaN summary\n",
        "    nan_count = X_train_fe.isnull().sum().sum()\n",
        "    nan_pct = nan_count / (X_train_fe.shape[0] * X_train_fe.shape[1])\n",
        "    print(f\"\\nMissing values:\")\n",
        "    print(f\"  Total NaN:    {nan_count:,} ({nan_pct:.2%})\")\n",
        "\n",
        "    # Feature groups\n",
        "    feature_groups = {\n",
        "        'APP': [c for c in X_train_fe.columns if not any(c.startswith(p) for p in ['BUREAU_', 'PREV_', 'APPROVED_', 'REFUSED_', 'POS_', 'INST_', 'CC_'])],\n",
        "        'BUREAU': [c for c in X_train_fe.columns if c.startswith('BUREAU_')],\n",
        "        'PREV': [c for c in X_train_fe.columns if c.startswith(('PREV_', 'APPROVED_', 'REFUSED_'))],\n",
        "        'POS': [c for c in X_train_fe.columns if c.startswith('POS_')],\n",
        "        'INST': [c for c in X_train_fe.columns if c.startswith('INST_')],\n",
        "        'CC': [c for c in X_train_fe.columns if c.startswith('CC_')]\n",
        "    }\n",
        "\n",
        "    print(f\"\\nFeature groups:\")\n",
        "    for group, cols in feature_groups.items():\n",
        "        print(f\"  {group:12s}: {len(cols):4,} features\")\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    return X_train_fe, X_test_fe, y_train\n"
      ],
      "metadata": {
        "id": "sjnTMNki7rWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 8. EXECUTION\n",
        "# ============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    paths = {\n",
        "        'app_train': os.path.join(DATA_DIR, \"application_train.csv\"),\n",
        "        'app_test': os.path.join(DATA_DIR, \"application_test.csv\"),\n",
        "        'bureau': os.path.join(DATA_DIR, \"bureau.csv\"),\n",
        "        'bureau_balance': os.path.join(DATA_DIR, \"bureau_balance.csv\"),\n",
        "        'prev': os.path.join(DATA_DIR, \"previous_application.csv\"),\n",
        "        'pos': os.path.join(DATA_DIR, \"POS_CASH_balance.csv\"),\n",
        "        'inst': os.path.join(DATA_DIR, \"installments_payments.csv\"),\n",
        "        'cc': os.path.join(DATA_DIR, \"credit_card_balance.csv\")\n",
        "    }\n",
        "\n",
        "    # Run pipeline\n",
        "    X_train_fe, X_test_fe, y_train = feature_engineering_pipeline(\n",
        "        app_train_path=paths['app_train'],\n",
        "        app_test_path=paths['app_test'],\n",
        "        bureau_path=paths['bureau'],\n",
        "        bureau_balance_path=paths['bureau_balance'],\n",
        "        prev_path=paths['prev'],\n",
        "        pos_path=paths['pos'],\n",
        "        inst_path=paths['inst'],\n",
        "        cc_path=paths['cc'],\n",
        "        output_dir=OUTPUT_DIR\n",
        "    )\n",
        "\n",
        "    print(\"\\n✓ Feature engineering completed successfully!\")\n",
        "    print(f\"  Files saved to: {OUTPUT_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLnohs657rUG",
        "outputId": "8661fd86-cb3d-47a7-f6bf-94981d37d073"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "FEATURE ENGINEERING PIPELINE\n",
            "================================================================================\n",
            "\n",
            "[1/8] Processing application_train...\n",
            "  Shape: (307511, 152)\n",
            "\n",
            "[2/8] Processing application_test...\n",
            "  Shape: (48744, 151)\n",
            "\n",
            "[3/8] Processing bureau + bureau_balance...\n",
            "  Shape: (305811, 74)\n",
            "\n",
            "[4/8] Processing previous_application...\n",
            "  Shape: (338857, 112)\n",
            "\n",
            "[5/8] Processing POS_CASH_balance...\n",
            "  Shape: (337252, 32)\n",
            "\n",
            "[6/8] Processing installments_payments...\n",
            "  Shape: (339587, 70)\n",
            "\n",
            "[7/8] Processing credit_card_balance...\n",
            "  Shape: (103558, 83)\n",
            "\n",
            "[8/8] Merging all tables...\n",
            "  Merging train dataset...\n",
            "    After bureau: (307511, 225)\n",
            "    After previous: (307511, 336)\n",
            "    After POS: (307511, 367)\n",
            "    After installments: (307511, 436)\n",
            "    After credit card: (307511, 518)\n",
            "  Merging test dataset...\n",
            "    Test shape: (48744, 517)\n",
            "\n",
            "[Post-processing] Handling missing values...\n",
            "  Filling 422 auxiliary columns with 0...\n",
            "\n",
            "[Export] Saving files...\n",
            "  Saved: /content/drive/MyDrive/home_credit/processed/X_train_fe.parquet\n",
            "  Saved: /content/drive/MyDrive/home_credit/processed/X_test_fe.parquet\n",
            "  Saved: /content/drive/MyDrive/home_credit/processed/y_train.parquet\n",
            "\n",
            "================================================================================\n",
            "FEATURE ENGINEERING COMPLETED\n",
            "================================================================================\n",
            "Training set:  307,511 rows × 517 features\n",
            "Test set:      48,744 rows × 517 features\n",
            "Target:        307,511 samples\n",
            "Target rate:   8.07%\n",
            "\n",
            "Feature types:\n",
            "  Numeric:      504\n",
            "  Categorical:  13\n",
            "\n",
            "Missing values:\n",
            "  Total NaN:    8,543,164 (5.37%)\n",
            "\n",
            "Feature groups:\n",
            "  APP         :  151 features\n",
            "  BUREAU      :   73 features\n",
            "  PREV        :  111 features\n",
            "  POS         :   31 features\n",
            "  INST        :   69 features\n",
            "  CC          :   82 features\n",
            "================================================================================\n",
            "\n",
            "✓ Feature engineering completed successfully!\n",
            "  Files saved to: /content/drive/MyDrive/home_credit/processed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tổng quan kết quả:\n",
        "\n",
        "- Training: 307,511 samples × 517 features\n",
        "- Test: 48,744 samples × 517 features\n",
        "- Target rate: 8.07% (imbalanced - cần xử lý khi modeling)"
      ],
      "metadata": {
        "id": "OtkJ-fTY4RVQ"
      }
    }
  ]
}